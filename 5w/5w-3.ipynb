{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 기계학습의 개념\n",
    "\n",
    "## 데이터들을 어떻게 설명할까?\n",
    "\n",
    "가설 : 데이터들을 설명하기 위해 데이터 양상을 직선으로 표현\n",
    "\n",
    "$y = Wx + b$\n",
    "\n",
    "## 기계학습의 훈련 \n",
    "\n",
    "예측을 가정 정확하게 할 수 있는 최적의 매개변수 $W,b$를 찾음.\n",
    "\n",
    "임의의 매개변수 값에서 시작하여, 개선해 나가면서 정량적인 최적의 성능에 도달함.\n",
    "\n",
    "![Alt text](./img/image.png)\n",
    "\n",
    "과정 :$f_1 \\to f_2 \\to f_3$ 을 거침"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 추론\n",
    "훈련을 마치면 `추론`을 수행\n",
    "\n",
    "    - 새로운 특징에 대응하는 목표치의 예측에 사용\n",
    "    - 10.0순간의 이동체 위치를 알고싶을 때 위 예시에서 결정 직선이 $f_3$로 정했다면, $f_3(10.0)$을 계산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 기계학습의 필수 요소\n",
    "\n",
    "- 학습할 수 있는 *데이터*가 있어야한다.\n",
    "- 데이터 규칙 존재 : 수학적인 규칙의 데이터 외에 노이즈나 이상치를 가지는 데이터도 많다.\n",
    "- 수학적으로 설명 불가능 \n",
    "\n",
    "## 특징공간\n",
    "\n",
    "- 모델 학습: 데이터 패턴을 가장 잘 설명하는 매개변수 찾기\n",
    "\n",
    "- d-차원 데이터 \n",
    "    - 특징벡터 : $(x_1,x_2,, ... ,x_d)^T$\n",
    "    - 직선 모델에서 매개변수 수 : $d+1$\n",
    "    - 2차원 곡선 모델을 사용하는 경우 매개변수 수 : $d^2+d+1$\n",
    "\n",
    "- 거리 : 차원에 무관하게 수식 적용 가능\n",
    "    - ex. 두 점 사이 거리는 모든 d에 대해 성립.\n",
    "    \n",
    "$\n",
    "\\sqrt{\\displaystyle\\sum_{i=1}^d{(a_i-b_i)^2}} \\\\\n",
    "(a = (a_1,a_2, ... ,a_d)^T, b = (b_1,b_2, ... , b_d)^T)\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 차원의 저주\n",
    "- 차원이 높아짐에 따라 발생하는 현실적 문제들\n",
    "- 차원이 높아질수록 유의미한 표현을 찾기 위해 지수적으로 많은 데이터가 필요함!\n",
    "\n",
    "![Alt text](./img/image-3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 특징 공간 변환\n",
    "![Alt text](./img/image-4.png)\n",
    "![Alt text](./img/image-5.png)\n",
    "변환된 특징 벡터와 같은 **변환**이 필요한데, 즉 어떻게 표현하냐의 문제이다.\n",
    "\n",
    "## 표현문제\n",
    "![Alt text](./img/image-6.png)\n",
    "변환 전에서는 이를 구분할 직선을 찾기 어려우나, **변환 후**가 되고 나서야 구분할 직선을 그릴 수 있게 된다.\n",
    "\n",
    "## 표현 학습\n",
    "- 좋은 특징 공간을 자동으로 찾는 방법\n",
    "\n",
    "## 심층 학습 (Deep learning)\n",
    "- 표현학습의 일종으로 표현학습을 계층적으로 수행. 즉, 신경망을 통해서 계층적으로 학습.\n",
    "- 추상적인 입력부터 간단한 형태의 입력까지 계층적 학습을 통해 모두 학습\n",
    "- image, Text, Speech에 대한 input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 인공신경망의 역사\n",
    "- 1940-1960 : 인공두뇌학. (퍼셉트론)\n",
    "- 1980-1990 : 결합설 (여러 퍼셉트론의 층 구성 : 과적합 문제)\n",
    "- 2006-오늘날 : 딥러닝 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 인공지능 범주\n",
    "- AI > ML > Representation learning > DL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 인공지능의 단계\n",
    "- Weak Ai : 인간이 지시한 명령의 틀 안에서만 일함. 예측과 관리가 용이함.\n",
    "- Strong Ai : 인간이 할 수 있는 어떠한 지적인 업무도 성공적으로 해낼 수 있는 (가상적인) 기계의 지능\n",
    "- Super Ai : 모든 인류의 지성을 합친 것보다 더 뛰어난 인공지능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터\n",
    "\n",
    "## 기계 학습\n",
    "- 복잡한 문제의 규칙을 찾아 과업을 이룸.\n",
    "- 단순한 수학공식으로 표현 불가능\n",
    "`즉, 데이터를 설명할 수 있는 학습 모델을 찾아가는 과정`\n",
    "이를 만들어 '예측(predict)'을 수행\\\n",
    "\n",
    "### 데이터 양과 질 \n",
    "- 주어진 과업에 대한 충분한 양만큼 수집해야 함. -> 과업 성능 향상 (데이터 양은 성능과 직결되는 것으로 본다.)\n",
    "- 공개 데이터 : 대표적으로 `Iris`, `MNIST`, `ImageNet`, UCI 저장소\n",
    "- `Iris` : 4가지 feature로 3개의 class를 분류\n",
    "- `MNIST` : 숫자 손글씨(train : 60,000, test : 10,000자)에 대한 10개의 class (0~9)로 분류\n",
    "- `ImageNet` : 21,841개에 대한 14,197,122개의 영상 보유. 1,000개 class로 classification을 하는 경진대회가 열렸었음.\n",
    "\n",
    "### 적은 양의 데이터로 어떻게 높은 성능을 달성할 수 있나?\n",
    "- MNIST : 각 픽셀 0 또는 1임을 감안하면 input:$28 \\times 28 \\to 2^{784}$ 가지 \n",
    "- 하지만 데이터는 6만개 뿐.(저차원)\n",
    "#### 매니폴드(많이+끼다) 가정 (manifold assumption)\n",
    "- 고차원 데이터(사진)는 유사하게 묶인 경우가 많다.\n",
    "- 즉, MNIST에서 target:2인 데이터에 대해 일정한 규칙(유사성)을 발견할 수 있게된다.\n",
    "- 따라서 랜덤한 Noise같은 경우 유사성이 없기 때문에 적은 데이터로 학습시킬 수 없다.\n",
    "\n",
    "### 데이터 가시화\n",
    "- 4차원 이상의 초공간은 한번에 가시화는 불가능하다.\n",
    "- 여러가지 가시화 기법 : 2,3차원의 가시화의 여러 결과를 나열\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## simple ML\n",
    "### 목적함수 : objective function\n",
    "(= 비용함수 : cost function)\n",
    "\n",
    "- 선형회귀를 위한 목적함수\n",
    "- ex. MSE : 평균 제곱 오차\n",
    "\n",
    " $J(Θ) = \\frac{1}{n}\\displaystyle\\sum_{i=1}^{n}{(f_Θ(x_i)-y_i)}^2$\n",
    "\n",
    "- $f_Θ(x_i)$ : predict값\n",
    "- $y_i$ : target값\n",
    "- $f_Θ(x_i)-y_i$ : 오차, 또는 손실\n",
    "\n",
    "`목적함수 값이 낮아진다는 건, 오차값이 낮아진다는 거겟쥬?`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "𝛳^ = $argmin J(Θ)$ : 즉, 손실함수가 최소화되는 최적의 𝛳를 찾는다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">선형을 이루는 데이터는 거의 없고 잡음이 섞인 경우가 빈번. 즉, 비선형모델이 필요하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기계 학습 요소\n",
    "- 카드 승인 예제\n",
    "\n",
    "|요소|기호|카드 승인 예제\n",
    "|:--:|:--:|:--:|\n",
    "|input|$x$|costomer application|\n",
    "|output|$y$|approve or deny|\n",
    "|target distribution|$f = P(y|x)$|ideal credit approval formular|\n",
    "|data|$(x_1,y_1),(x_2,y_2),\\cdots,(x_N,y_N)$|historical records|\n",
    "|hypothesis|$g:X\\to y$|fomula to be used|\n",
    "\n",
    "> - target distribution은 우리가 알지 못한다. \n",
    "- $f = P(y|x)$ : $x$(input)이 주어졌을 때 class별 확률을 유추하려 함. (생성 원리 유추)\n",
    "- 유추 시, 수집된 data를 통해 눈에 보이지 않는 생성 분포($f = P(y|x)$)을 설명하는 게 목표 - 가설(hypothesis) 형성 = 규칙 생성\n",
    "- 가설을 다시말해, **모델**($g$)이라고 하며 모델에 적절한 파라미터를 찾아가는 과정이 기계학습의 훈련(train)과 추론과정\n",
    "\n",
    "![Alt text](image-1.png)\n",
    "\n",
    "예시에서, 11개의 데이터에 대해, 두개의 feature(age, salary)만을 고려하여 분류모델을 설계한다고 본다.\n",
    ">- $g$라는 선을 **가설**로 그어버린다.\n",
    ">- 예측값과 실제값을 통해 오차를 최소화 하고자 하는 성능을 가지는 모델을 찾아간다.(학습)\n",
    ">- 최적화된 성능을 가진 모델 $f$를 유추하고자 한다.\n",
    "\n",
    "\n",
    "- 교사학습(Supervised learning)의 경우 \n",
    "\n",
    "![Alt text](image-3.png)\n",
    "- flow\n",
    ">- $x,y$가 주어지고 $f$라는 target distribution을 통해 $y$를 생성\n",
    ">- 이 target distribution를 우리는 모른다.\n",
    ">- Training data set(training examples)을 통해 target distribution을 맞추려 함.\n",
    ">- input distribution(데이터의 분포): 데이터 자체가 생성되는 규칙\n",
    ">- target distribution : 주어진 데이터에서 $y$를 만들면서 생성되는 규칙(x와 y사이의 상관관계)을 파악하여 유추 : supervised learning(교사학습)\n",
    ">- $cf.$ x와 y사이의 상관관계가 없는 경우, input distribution만 보고 유추하는 경우 : unsupervised learing(비교사 학습)\n",
    "- 목적 함수 : 성능 지표 - 신경망에서 반드시 필요. \n",
    "- 가설 : 선형 회귀 모델이면, 직선으로 모델(가설)을 세우며, 이를 목적함수값이 최소화되도록 하며 약간씩 조정. 이를 통해 최적화된 모델을 찾아감.\n",
    "\n",
    "### 모델 선택\n",
    "\n",
    "- 과소 적합\n",
    "> 모델의 '용량'이 작아 오차가 클 수 밖에 없는 상황. : 학습이 덜 됨.\n",
    "- 용량 : 모델의 파라미터 수와 비례해 모델 용량의 크기가 결정되는데, under fitting을 방지하기 위해 파라미터 수를 늘릴 수 있다.\n",
    "- 대안 : 비선형 모델을 사용.\n",
    "![Alt text](image-4.png)\n",
    "이처럼 용량을 늘려 오차를 더 감소 시킬 수 있다. \n",
    ">- 용량이 늘어나므로 모델의 자유도가 늘어난다.\n",
    ">- 파라미터에 대한 충분한 학습이 필요하므로, 더 많은 데이터를 필요로 한다.\n",
    "\n",
    "- 과잉 적합\n",
    "> - train 데이터에 거의 완벽한 근사화가 이루어져 있음.\n",
    "- 하지만 새로운 데이터(ex. test data)에 대한 예측에선 큰 문제가 발생함.\n",
    "- 학습 과정에서, 특정 데이터에 대한 치우침 혹은 노이즈까지 수용해버린 것.\n",
    "- 훈련집합에 대한 단순암기 상태\n",
    "\n",
    "- 1~2차 : 훈련집합과 테스트 집합 모두 낮은 성능 : 과소적합\n",
    "- 12차 : 훈련집합에서는 높은 성능을 보이나, 테스트 집합에서는 낮은 성능 -> 일반화 능력 낮음 : 과잉적합.\n",
    "- 3~4차 : 훈련집합에 대해 12차보다는 낮은 성능이나, 테스트 집합에서는 보다 높은 성능 -> 높은 일반화 능력. 적합 모델 선택할 수 있음.\n",
    "![Alt text](image-5.png)\n",
    "- 즉, 용량(capacity)이 커진다고(파라미터 수가 많아진다고)해서 성능이 커지는 것은 아니다.\n",
    "- 딥러닝에서는 모델의 용량을 줄이도록 **규제(regularizer)**를 적용\n",
    "\n",
    "- 훈련 집합에 대한 세가지 모델 적합도 예시.\n",
    "![Alt text](image-6.png)\n",
    "Train 데이터가 전체 데이터를 모두 설명할 수 없기때문에 생기는 문제.\n",
    "\n",
    "## 편향(Bias)과 분산(Variance)\n",
    "![Alt text](image-7.png)\n",
    "- 2차 모델은 큰 오차가 존재 : 편향이 큼. 하지만 비슷한 모델을 얻음(낮은 분산)(= 변동이 낮음)\n",
    "- 12차 모델은 매번 작은 오차 : 편향이 작음. 하지만 훈련집합 마다 모델이 크게 달라짐(높은 분산)(=변동이 큼)\n",
    "- 일반적으로 용량이 작은 모델은 편향이 크고 분산이 작다.\n",
    "- 복잡한 모델은 편향이 작고 분산이 크다.\n",
    "\n",
    "![Alt text](image-8.png)\n",
    "\n",
    "> 기계학습의 목표 : 낮은 편향과 낮은 분산을 가진 예측 모델을 만드는 것.\n",
    "\n",
    "- 실제로는 모델의 편향과 분산은 반비례 관계이다.\n",
    "\n",
    "\n",
    "### 편향과 분산의 관계\n",
    "![Alt text](image-9.png)\n",
    "- 용량 증가 -> 편향 감소, 분산 증가하는 경향\n",
    "- 일반화 오차 성능(=편향+분산)은 U자형의 곡선을 가진다.\n",
    "- - 편향을 최소로 유지하며 분산도 최대한 낮추는 전략이 필요한데, 최적화(optimal)된 지점을 찾기위한 전략엔 뭐가 있을까?\n",
    "\n",
    "## Validation set\n",
    "검증 집합을 통한 모델 선택 (데이터 양 많을 때)\n",
    "![Alt text](image-10.png)\n",
    "- 알고리즘\n",
    ">1. 각각의 모델에 대해 모두 훈련집합으로 학습시킨다.\n",
    ">2. 검증 집합으로 학습된 모델의 성능을 측정한다. (test대신 validation)\n",
    ">3. 가장 높은 성능을 보인 모델을 선택\n",
    ">4. 테스트 집합으로 선택된 모델의 성능을 측정함.\n",
    "\n",
    "## Cross Validation\n",
    "별도의 검증 집합이 없는 상황에 유용한 모델 선택 방법(**데이터가 적음**). 훈련집합을 등분해, 학습과 편과 과정을 여러번 반복수행한 후 평균을 구해 사용\n",
    "\n",
    "- 알고리즘\n",
    "![Alt text](image-11.png)\n",
    ">1. Train set을 k개의 그룹으로 등분 \n",
    ">2. 모든 각각의 모델에 대해, i(1~k)번째 데이터를 validation set으로 삼고, 나머지 k-1 그룹으로 학습시킨다. 학습된 모델의 성능을 i번째 데이터로 측정한다.\n",
    ">3. 이후 각 성능에 대한 평균을 구한다. 다음 모델로 넘어가서 2~3번을 반복한다.\n",
    ">4. 가장 높은 성능을 보인 모델을 취해 Test data로 모델 성능을 측정한다.\n",
    "\n",
    "## Booststrap\n",
    "임의의 **복원 추출** 샘플링 반복\n",
    "- 데이터 분포가 불균형할 때\n",
    ">Ex. 이상탐지, 보안\n",
    "\n",
    "![Alt text](image-12.png)\n",
    "- $Input$ : 모델집합 $\\Omega$, train, test, 샘플링 비율 $p(0<p≤1)$, 반복횟수 $T$\n",
    "- $Output$ : 최적 모델 성능\n",
    "- 알고리즘 \n",
    ">1. 모든 각각의 모델($\\Omega$)에 대해 각 모델에서 Train data($X$)에서의 $p$만큼만을 뽑아 새로운 Train data($X^*$)를 구성한다.\n",
    ">2. $X^*$로 모델학습 진행\n",
    ">3. $X-X^*$를 이용해 학습된 모델의 성능 측정.\n",
    ">4. 2~3번을 $T$번 반복\n",
    ">5. 1~4번 중에서 가장 높은 성능의 모델을 취해 test data로 성능 측정.\n",
    "\n",
    "- 용량이 충분히 큰 모델은 선택한 후, 이 모델이 정상을 벗어나지 않도록 여러 규제(regularization)기법을 적용한다.\n",
    "\n",
    "## 규제\n",
    "대표적인 두가지 방법을 알아보자!\n",
    "\n",
    "### 데이터 확대(data argumentation)\n",
    "데이터를 더 많이 수집해 일반화 능력을 향상시킨다.\n",
    ">- 개요\n",
    "![Alt text](image-13.png)\n",
    ">- data는 target에서 비롯이 되는데, 데이터를 많이 수집할 수록(훈련집합의 증가) target에 대한 정보가 많아진다고 볼 수 있다.\n",
    ">- 모델 용량이 커도(분산이 클 수 있는 경우) 훈련집합이 많아지면 모델 변동량이 (c)처럼 줄어들 수 있다. (분산 작아짐)\n",
    "\n",
    "- 하지만, 데이터 수집은 많은 비용이 든다. (실측자료 Ground Truth를 사람이 수작업해서 labeling해야함.)\n",
    "- 따라서 인위적으로 데이터 양을 확대시킨다.\n",
    "![Alt text](image-14.png)\n",
    "- 이처럼 원본 데이터를 약간 회전(rotation)하거나, 왜곡(warping)시킨다. 단, 원본 데이터의 class등의 고유 특성 변하지 않는 한에서 진행.\n",
    "\n",
    "### 가중치 감쇠\n",
    "가중치를 작게 조절하는 방법이다. 즉, 모델의 용량이 큰 가중치를 낮춤으로 모델 용량 크기를 조정해 overfitting될 요소를 줄일 수 있는 것.\n",
    "- 예시 : 12차 곡선\n",
    "> $y = 1005.1x^{12}- 2774.4x^{11} + \\cdots - 22852612.5x^1 - 12.8$\n",
    "\n",
    "- 가중치 감쇠는 개선된 **목적함수**를 이용해 가중치를 작게 조절하는 규제 기법이다.\n",
    "> $\\frac{1}{n}\\sum_{i=1}^n(f_\\theta(x_i)-y_i)^2 + \\lambda\\|\\theta\\|^2_2$\n",
    "- 이와같이 규제항 $\\lambda\\|\\theta\\|^2_2$을 추가해 가중치 크기를 작게 유지한다.\n",
    "- 결과(예시)\n",
    "> $y = 10.779x^{12}- 42.732x^{11} + \\cdots - 2.379x^1 - 0.119$\n",
    "\n",
    "![Alt text](image-15.png)\n",
    "- 선호(preference) : 각 항의 가중치 중, 특정 항의 가중치가 발현되지 못하게 $\\omega$에 대한 함수를 넣어 가중치$\\omega$를 낮추려 함.\n",
    "- $\\lambda$ : 주어진 가중치의 감쇠 preference 정도를 제어함.\n",
    "> - $\\lambda=0$ : 감쇠가 없음\n",
    ">- $\\lambda$가 클수록 가중치가 더 작아지도록 한다.\n",
    ">- $\\lambda$에 따른 모델 변화\n",
    ">![Alt text](image-16.png)\n",
    "\n",
    "## 학습 유형에 따른 분류\n",
    "### 지도학습 : Supervised learning\n",
    ">- 특징 벡터(data : $X$)와 목표치(target : $y$)가 모두 주어져 있다.\n",
    ">- **회귀**($y$ : numerical) 와 **분류**($y$ : categorical)문제로 구분\n",
    "\n",
    "### 비지도학습 : Unsupervised learning\n",
    ">- 특징 벡터(data : $X$)는 주어지나, 목표치(target : $y$)는 주어지지 않는 상황.\n",
    ">- **군집화**(clustering)과업 (고객 성향에 따른 맞춤 홍보 : 추천시스템 RecSys)\n",
    ">- **밀도추정**(density estimation), **특징 공간 변형**(ex. PCA) : 원공간($X$)에 대한 이해가 필요.\n",
    "\n",
    "### 강화학습 : reinforcement learning\n",
    ">- 상대적 목표치가 주어짐. (보상 reward)\n",
    ">- ex. 바둑\n",
    "    - 수를 두는 행위 : sample. 게임이 끝나면 목표치가 부여됨. (이기면 1, 지면 -1)\n",
    "    - 게임을 구성한 샘플들 각각에 목표치를 나누어 주어야 함.\n",
    "    \n",
    "### 준지도 학습 : semi-supervised learning\n",
    ">- 일부는 data : $X$와 $y$를 모두 가지지만, 나머지는 $X$만 가지는 상황\n",
    "\n",
    "## 다양한 기준에 따른 유형\n",
    "### 오프라인 학습과 온라인 학습\n",
    "- 보통 오프라인 학습\n",
    "- 온라인 학습은 IoT등에서 추가로 발생하는 데이터 샘플을 가지고 점증적 학습 수행.\n",
    "\n",
    "### 결정론적 학습과 확률적 학습\n",
    "- 결정론적 : 같은 데이터를 가지고 다시 학습 시, 같은 예측 모델이 만들어짐.\n",
    "- 확률적 : 학습 과정에서 **확률 분포**사용. 같은 데이터로 다시 학습 시, 다른 예측 모델이 만들어짐.\n",
    "- Ex. RBM, DBN\n",
    "\n",
    "### 분별 모델과 생성 모델\n",
    "- 분별 : class 예측에만 관심을 가짐. 즉, $P(y|x)$의 추정에만 관심있음.\n",
    "- 생성 : $P(x)$, $P(x|y)$를 추정한다.\n",
    "    - 따라서 새로운 샘플을 생성할 수 있다.\n",
    "    - Ex. GAN, RBM, 순환신경망(RNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
